digraph {
	graph [size="27.75,27.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2874532940592 [label="
 (1, 16, 64)" fillcolor=darkolivegreen1]
	2874532785120 [label="AddBackward0
------------
alpha: 1"]
	2874532784640 -> 2874532785120
	2874532784640 [label="ViewBackward0
------------------------
self_sym_sizes: (16, 64)"]
	2874532784832 -> 2874532784640
	2874532784832 -> 2874519142048 [dir=none]
	2874519142048 [label="mat1
 (16, 64)" fillcolor=orange]
	2874532784832 -> 2874532941152 [dir=none]
	2874532941152 [label="mat2
 (64, 64)" fillcolor=orange]
	2874532784832 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (16, 64)
mat1_sym_strides:        (64, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (64, 64)
mat2_sym_strides:        (1, 64)"]
	2874532784400 -> 2874532784832
	2874532939792 [label="attn.proj.bias
 (64)" fillcolor=lightblue]
	2874532939792 -> 2874532784400
	2874532784400 [label=AccumulateGrad]
	2874532785072 -> 2874532784832
	2874532785072 [label="ViewBackward0
---------------------------
self_sym_sizes: (1, 16, 64)"]
	2874532785840 -> 2874532785072
	2874532785840 [label="UnsafeViewBackward0
------------------------------
self_sym_sizes: (1, 16, 4, 16)"]
	2874532928864 -> 2874532785840
	2874532928864 [label=CloneBackward0]
	2874532928960 -> 2874532928864
	2874532928960 [label="TransposeBackward0
------------------
dim0: 1
dim1: 2"]
	2874532928768 -> 2874532928960
	2874532928768 [label="UnsafeViewBackward0
---------------------------
self_sym_sizes: (4, 16, 16)"]
	2874532929200 -> 2874532928768
	2874532929200 -> 2874532941232 [dir=none]
	2874532941232 [label="mat2
 (4, 16, 16)" fillcolor=orange]
	2874532929200 -> 2874532941312 [dir=none]
	2874532941312 [label="self
 (4, 16, 16)" fillcolor=orange]
	2874532929200 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	2874532929488 -> 2874532929200
	2874532929488 [label="ReshapeAliasBackward0
------------------------------
self_sym_sizes: (1, 4, 16, 16)"]
	2874533036192 -> 2874532929488
	2874533036192 [label="ExpandBackward0
------------------------------
self_sym_sizes: (1, 4, 16, 16)"]
	2874533036288 -> 2874533036192
	2874533036288 -> 2874532941472 [dir=none]
	2874532941472 [label="result
 (1, 4, 16, 16)" fillcolor=orange]
	2874533036288 [label="SoftmaxBackward0
----------------------
dim   :     4294967295
result: [saved tensor]"]
	2874533036480 -> 2874533036288
	2874533036480 -> 2874532941632 [dir=none]
	2874532941632 [label="other
 ()" fillcolor=orange]
	2874533036480 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	2874533036624 -> 2874533036480
	2874533036624 [label="UnsafeViewBackward0
---------------------------
self_sym_sizes: (4, 16, 16)"]
	2874533036720 -> 2874533036624
	2874533036720 -> 2874532941552 [dir=none]
	2874532941552 [label="mat2
 (4, 16, 16)" fillcolor=orange]
	2874533036720 -> 2874532941392 [dir=none]
	2874532941392 [label="self
 (4, 16, 16)" fillcolor=orange]
	2874533036720 [label="BmmBackward0
--------------------
mat2: [saved tensor]
self: [saved tensor]"]
	2874533036864 -> 2874533036720
	2874533036864 [label="ReshapeAliasBackward0
------------------------------
self_sym_sizes: (1, 4, 16, 16)"]
	2874533037008 -> 2874533036864
	2874533037008 [label="ExpandBackward0
------------------------------
self_sym_sizes: (1, 4, 16, 16)"]
	2874533037104 -> 2874533037008
	2874533037104 [label="PermuteBackward0
------------------
dims: (0, 2, 1, 3)"]
	2874533037152 -> 2874533037104
	2874533037152 [label="ReshapeAliasBackward0
---------------------------
self_sym_sizes: (1, 16, 64)"]
	2874533037296 -> 2874533037152
	2874533037296 [label="UnsafeViewBackward0
------------------------
self_sym_sizes: (16, 64)"]
	2874533037440 -> 2874533037296
	2874533037440 -> 2874533040512 [dir=none]
	2874533040512 [label="mat2
 (64, 64)" fillcolor=orange]
	2874533037440 -> 2874533040192 [dir=none]
	2874533040192 [label="self
 (16, 64)" fillcolor=orange]
	2874533037440 [label="MmBackward0
--------------------------------
mat2            : [saved tensor]
mat2_sym_sizes  :       (64, 64)
mat2_sym_strides:        (1, 64)
self            : [saved tensor]
self_sym_sizes  :       (16, 64)
self_sym_strides:        (64, 1)"]
	2874533037728 -> 2874533037440
	2874533037728 [label="ReshapeAliasBackward0
---------------------------
self_sym_sizes: (1, 16, 64)"]
	2874533037872 -> 2874533037728
	2874533037872 -> 2874442233312 [dir=none]
	2874442233312 [label="bias
 (64)" fillcolor=orange]
	2874533037872 -> 2874502084064 [dir=none]
	2874502084064 [label="input
 (1, 16, 64)" fillcolor=orange]
	2874533037872 -> 2874533040832 [dir=none]
	2874533040832 [label="result1
 (1, 16, 1)" fillcolor=orange]
	2874533037872 -> 2874533040432 [dir=none]
	2874533040432 [label="result2
 (1, 16, 1)" fillcolor=orange]
	2874533037872 -> 2874442233392 [dir=none]
	2874442233392 [label="weight
 (64)" fillcolor=orange]
	2874533037872 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (64,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2874533038064 -> 2874533037872
	2874442233392 [label="norm_q.weight
 (64)" fillcolor=lightblue]
	2874442233392 -> 2874533038064
	2874533038064 [label=AccumulateGrad]
	2874533037920 -> 2874533037872
	2874442233312 [label="norm_q.bias
 (64)" fillcolor=lightblue]
	2874442233312 -> 2874533037920
	2874533037920 [label=AccumulateGrad]
	2874533037584 -> 2874533037440
	2874533037584 [label=TBackward0]
	2874533038112 -> 2874533037584
	2874532850480 [label="attn.q.weight
 (64, 64)" fillcolor=lightblue]
	2874532850480 -> 2874533038112
	2874533038112 [label=AccumulateGrad]
	2874533036768 -> 2874533036720
	2874533036768 [label="ReshapeAliasBackward0
------------------------------
self_sym_sizes: (1, 4, 16, 16)"]
	2874533036912 -> 2874533036768
	2874533036912 [label="ExpandBackward0
------------------------------
self_sym_sizes: (1, 4, 16, 16)"]
	2874533037392 -> 2874533036912
	2874533037392 [label="TransposeBackward0
------------------
dim0: 4294967294
dim1: 4294967295"]
	2874533037776 -> 2874533037392
	2874533037776 [label="PermuteBackward0
------------------
dims: (0, 2, 1, 3)"]
	2874533038160 -> 2874533037776
	2874533038160 [label="ReshapeAliasBackward0
---------------------------
self_sym_sizes: (1, 16, 64)"]
	2874533038256 -> 2874533038160
	2874533038256 [label="UnsafeViewBackward0
------------------------
self_sym_sizes: (16, 64)"]
	2874533038352 -> 2874533038256
	2874533038352 -> 2874533040752 [dir=none]
	2874533040752 [label="mat2
 (64, 64)" fillcolor=orange]
	2874533038352 -> 2874533040992 [dir=none]
	2874533040992 [label="self
 (16, 64)" fillcolor=orange]
	2874533038352 [label="MmBackward0
--------------------------------
mat2            : [saved tensor]
mat2_sym_sizes  :       (64, 64)
mat2_sym_strides:        (1, 64)
self            : [saved tensor]
self_sym_sizes  :       (16, 64)
self_sym_strides:        (64, 1)"]
	2874533038448 -> 2874533038352
	2874533038448 [label="ReshapeAliasBackward0
---------------------------
self_sym_sizes: (1, 16, 64)"]
	2874533038592 -> 2874533038448
	2874533038592 -> 2874532850720 [dir=none]
	2874532850720 [label="bias
 (64)" fillcolor=orange]
	2874533038592 -> 2874487554672 [dir=none]
	2874487554672 [label="input
 (1, 16, 64)" fillcolor=orange]
	2874533038592 -> 2874533041232 [dir=none]
	2874533041232 [label="result1
 (1, 16, 1)" fillcolor=orange]
	2874533038592 -> 2874533040672 [dir=none]
	2874533040672 [label="result2
 (1, 16, 1)" fillcolor=orange]
	2874533038592 -> 2874532849520 [dir=none]
	2874532849520 [label="weight
 (64)" fillcolor=orange]
	2874533038592 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (64,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2874533038736 -> 2874533038592
	2874532849520 [label="norm_kv.weight
 (64)" fillcolor=lightblue]
	2874532849520 -> 2874533038736
	2874533038736 [label=AccumulateGrad]
	2874533038640 -> 2874533038592
	2874532850720 [label="norm_kv.bias
 (64)" fillcolor=lightblue]
	2874532850720 -> 2874533038640
	2874533038640 [label=AccumulateGrad]
	2874533038400 -> 2874533038352
	2874533038400 [label=TBackward0]
	2874533038784 -> 2874533038400
	2874532850560 [label="attn.k.weight
 (64, 64)" fillcolor=lightblue]
	2874532850560 -> 2874533038784
	2874533038784 [label=AccumulateGrad]
	2874532929344 -> 2874532929200
	2874532929344 [label="ReshapeAliasBackward0
------------------------------
self_sym_sizes: (1, 4, 16, 16)"]
	2874533036336 -> 2874532929344
	2874533036336 [label="ExpandBackward0
------------------------------
self_sym_sizes: (1, 4, 16, 16)"]
	2874533036672 -> 2874533036336
	2874533036672 [label="PermuteBackward0
------------------
dims: (0, 2, 1, 3)"]
	2874533037056 -> 2874533036672
	2874533037056 [label="ReshapeAliasBackward0
---------------------------
self_sym_sizes: (1, 16, 64)"]
	2874533037536 -> 2874533037056
	2874533037536 [label="UnsafeViewBackward0
------------------------
self_sym_sizes: (16, 64)"]
	2874533037824 -> 2874533037536
	2874533037824 -> 2874533041312 [dir=none]
	2874533041312 [label="mat2
 (64, 64)" fillcolor=orange]
	2874533037824 -> 2874533041472 [dir=none]
	2874533041472 [label="self
 (16, 64)" fillcolor=orange]
	2874533037824 [label="MmBackward0
--------------------------------
mat2            : [saved tensor]
mat2_sym_sizes  :       (64, 64)
mat2_sym_strides:        (1, 64)
self            : [saved tensor]
self_sym_sizes  :       (16, 64)
self_sym_strides:        (64, 1)"]
	2874533036960 -> 2874533037824
	2874533036960 [label="ReshapeAliasBackward0
---------------------------
self_sym_sizes: (1, 16, 64)"]
	2874533038832 -> 2874533036960
	2874533038832 -> 2874532850720 [dir=none]
	2874532850720 [label="bias
 (64)" fillcolor=orange]
	2874533038832 -> 2874487554672 [dir=none]
	2874487554672 [label="input
 (1, 16, 64)" fillcolor=orange]
	2874533038832 -> 2874533041552 [dir=none]
	2874533041552 [label="result1
 (1, 16, 1)" fillcolor=orange]
	2874533038832 -> 2874533041152 [dir=none]
	2874533041152 [label="result2
 (1, 16, 1)" fillcolor=orange]
	2874533038832 -> 2874532849520 [dir=none]
	2874532849520 [label="weight
 (64)" fillcolor=orange]
	2874533038832 [label="NativeLayerNormBackward0
--------------------------------
bias            : [saved tensor]
input           : [saved tensor]
normalized_shape:          (64,)
result1         : [saved tensor]
result2         : [saved tensor]
weight          : [saved tensor]"]
	2874533038736 -> 2874533038832
	2874533038640 -> 2874533038832
	2874533038304 -> 2874533037824
	2874533038304 [label=TBackward0]
	2874533038544 -> 2874533038304
	2874532850640 [label="attn.v.weight
 (64, 64)" fillcolor=lightblue]
	2874532850640 -> 2874533038544
	2874533038544 [label=AccumulateGrad]
	2874532784592 -> 2874532784832
	2874532784592 [label=TBackward0]
	2874532928912 -> 2874532784592
	2874532939712 [label="attn.proj.weight
 (64, 64)" fillcolor=lightblue]
	2874532939712 -> 2874532928912
	2874532928912 [label=AccumulateGrad]
	2874532785120 -> 2874532940592
}
