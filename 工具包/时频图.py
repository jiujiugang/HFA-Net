import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pywt
from scipy.signal import butter, lfilter, resample
import matplotlib

matplotlib.rcParams['font.sans-serif'] = ['SimHei']
matplotlib.rcParams['axes.unicode_minus'] = False


# ==========================================================
# æ»¤æ³¢å™¨å®šä¹‰
# ==========================================================
def butter_lowpass_filter(data, cutoff_freq, sampling_rate, order=4):
    """ä½é€šæ»¤æ³¢å™¨ï¼ˆRESPï¼‰"""
    nyquist = 0.5 * sampling_rate
    normal_cutoff = cutoff_freq / nyquist
    b, a = butter(order, normal_cutoff, btype='low', analog=False)
    return lfilter(b, a, data)


def signal_filter(data, frequency, highpass=50, lowpass=0.5):
    """å¸¦é€šæ»¤æ³¢å™¨ï¼ˆECGï¼‰"""
    b, a = butter(3, [lowpass / frequency * 2, highpass / frequency * 2], 'bandpass')
    return lfilter(b, a, data)


# ==========================================================
# å›¾åƒä¿å­˜å‡½æ•°
# ==========================================================
def save_no_axis_cwt_image(power, extent, save_path):
    """ä¿å­˜æ— åæ ‡å›¾"""
    fig = plt.figure(figsize=(3, 3))
    plt.imshow(power, extent=extent, aspect='auto', cmap='jet', origin='lower')
    plt.axis('off')
    plt.tight_layout(pad=0)
    plt.savefig(save_path, dpi=300, bbox_inches='tight', pad_inches=0)
    plt.close()


# ==========================================================
# Morlet å°æ³¢å˜æ¢ä¸ä¿å­˜
# ==========================================================
def crop_and_save_cwt(signal, fs, signal_type, subject_id, emotion, segment_idx, time_range, save_dir_no_axis):
    """ä½¿ç”¨ Morlet å°æ³¢è®¡ç®— CWT å¹¶ä¿å­˜"""
    signal = signal - np.mean(signal)
    signal = signal / (np.std(signal) + 1e-8)

    # å…³é”®é¢‘åŸŸ
    if signal_type.upper() == 'RESP':
        f_min, f_max, num_scales = 0.05, 0.4, 256
    elif signal_type.upper() == 'ECG':
        f_min, f_max, num_scales = 0.5, 45, 256
    else:
        raise ValueError("signal_type must be 'RESP' or 'ECG'")

    freqs = np.linspace(f_min, f_max, num_scales)
    fc = pywt.central_frequency('morl')
    scales = fc * fs / freqs

    coef, _ = pywt.cwt(signal, scales, 'morl', sampling_period=1 / fs)
    power = np.abs(coef) ** 2
    power -= np.min(power)
    if np.max(power) != 0:
        power /= np.max(power)
    power = np.power(power, 0.8)  # Î³å¢å¼º

    time = np.linspace(0, len(signal) / fs, len(signal))
    extent = [time[0], time[-1], freqs.min(), freqs.max()]

    os.makedirs(os.path.join(save_dir_no_axis, emotion), exist_ok=True)
    save_path = os.path.join(save_dir_no_axis, emotion,
                             f"{subject_id}_{emotion}_seg{segment_idx}_{signal_type}.png")
    save_no_axis_cwt_image(power, extent, save_path)

    print(f"âœ… å·²ä¿å­˜ {signal_type} æ—¶é¢‘å›¾: seg{segment_idx} | æ—¶é—´æ®µ: {time_range[0]:.2f}â€“{time_range[1]:.2f} s")


# ==========================================================
# ä¸»å¤„ç†æµç¨‹
# ==========================================================
base_data_dir = "D:/æ–‡çŒ®å¤ç°/WESAD"
emotion_folders = {
    "Baseline": os.path.join(base_data_dir, "Baseline"),
    "Stress": os.path.join(base_data_dir, "Stress"),
    "Happy": os.path.join(base_data_dir, "Happy"),
}

resp_output_path = r"E:\ä¸‰ä¸ªæ•°æ®åº“å¤„ç†çš„æ•°æ®\æ—¶é¢‘å›¾Morletåæ¨\RESP"
ecg_output_path = r"E:\ä¸‰ä¸ªæ•°æ®åº“å¤„ç†çš„æ•°æ®\æ—¶é¢‘å›¾Morletåæ¨\ECG"

fs_original = 700
fs_target_ecg = 360
fs_target_resp = 100
segment_duration = 60  # æ¯æ®µ 60 s

stats_dict = {}

for emotion, folder_path in emotion_folders.items():
    print(f"\nğŸ“‚ æ­£åœ¨å¤„ç†æƒ…ç»ªï¼š{emotion}")
    file_list = [f for f in os.listdir(folder_path) if f.endswith('.pkl')]

    for file_name in file_list:
        try:
            file_path = os.path.join(folder_path, file_name)
            data = pd.read_pickle(file_path)
            subject_id = file_name.split('_')[0]

            # ECG æ»¤æ³¢ + é‡é‡‡æ ·
            ecg = data['ECG'].values.flatten()
            ecg_filtered = signal_filter(ecg, frequency=fs_original)
            ecg_resampled = resample(ecg_filtered, int(len(ecg_filtered) * fs_target_ecg / fs_original))

            # RESP æ»¤æ³¢ + é‡é‡‡æ ·
            resp = data['RESP'].values.flatten()
            resp_filtered = butter_lowpass_filter(resp, cutoff_freq=0.4, sampling_rate=fs_original)
            resp_resampled = resample(resp_filtered, int(len(resp_filtered) * fs_target_resp / fs_original))

            # ================= ä»åå¾€å‰åˆ†æ®µ =================
            seg_len_ecg = int(segment_duration * fs_target_ecg)
            seg_len_resp = int(segment_duration * fs_target_resp)

            num_seg_ecg = len(ecg_resampled) // seg_len_ecg
            num_seg_resp = len(resp_resampled) // seg_len_resp

            ecg_total_time = len(ecg_resampled) / fs_target_ecg
            resp_total_time = len(resp_resampled) / fs_target_resp

            ecg_count, resp_count = 0, 0

            # ECG: ä»åå¾€å‰å–
            for i in range(num_seg_ecg):
                end = ecg_total_time - i * segment_duration
                start = end - segment_duration
                start_idx = int(start * fs_target_ecg)
                end_idx = int(end * fs_target_ecg)

                segment = ecg_resampled[start_idx:end_idx]
                if len(segment) == seg_len_ecg:
                    crop_and_save_cwt(segment, fs_target_ecg, 'ECG',
                                      subject_id, emotion, i + 1, (start, end), ecg_output_path)
                    ecg_count += 1

            # RESP: ä»åå¾€å‰å–
            for i in range(num_seg_resp):
                end = resp_total_time - i * segment_duration
                start = end - segment_duration
                start_idx = int(start * fs_target_resp)
                end_idx = int(end * fs_target_resp)

                segment = resp_resampled[start_idx:end_idx]
                if len(segment) == seg_len_resp:
                    crop_and_save_cwt(segment, fs_target_resp, 'RESP',
                                      subject_id, emotion, i + 1, (start, end), resp_output_path)
                    resp_count += 1

            # ç»Ÿè®¡
            if subject_id not in stats_dict:
                stats_dict[subject_id] = {'ECG': 0, 'RESP': 0}
            stats_dict[subject_id]['ECG'] += ecg_count
            stats_dict[subject_id]['RESP'] += resp_count

            print(f"ğŸ¯ å®Œæˆ {file_name} | ECG æ®µæ•°={ecg_count}, RESP æ®µæ•°={resp_count}")

        except Exception as e:
            print(f"âŒ é”™è¯¯ï¼š{file_name}, ä¿¡æ¯ï¼š{e}")


# ==========================================================
# æ±‡æ€»ç»Ÿè®¡
# ==========================================================
print("\nğŸ“Š å„è¢«è¯•ç”Ÿæˆçš„æ—¶é¢‘å›¾æ•°é‡ï¼š")
for sid, counts in sorted(stats_dict.items()):
    print(f"  {sid}: ECG={counts['ECG']} å¼ , RESP={counts['RESP']} å¼ ")

total_ecg = sum(v['ECG'] for v in stats_dict.values())
total_resp = sum(v['RESP'] for v in stats_dict.values())
print(f"\nâœ… æ€»è®¡: ECG={total_ecg} å¼ , RESP={total_resp} å¼ ")

