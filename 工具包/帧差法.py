import os
import sys
import cv2
import numpy as np
import pandas as pd
import face_recognition.api as face_recognition
import matplotlib.pyplot as plt
from tqdm import tqdm

data_root = r'D:\HTNet-master\NEW_MODEL\CASME_3'                                      # æ•°æ®é›†æ‰€åœ¨çš„æ ¹ç›®å½• ä¸ºSMICæ•°æ®é›†è£å‰ªåçš„å›¾ç‰‡çš„é¡¶ç‚¹å¸§æ£€æµ‹
annotation_file = r'/NEW_MODEL/CAS(ME)3_part_C_ME.xlsx'  # æ•°æ®é›†çš„æ³¨é‡Šæ–‡ä»¶åç§°
label_dict = {'negative': 0, 'positive': 1, 'surprise': 2}                  # å®šä¹‰ç±»åˆ«ä¸æ•°å­—ç¼–ç ä¹‹é—´çš„å¯¹åº”å…³ç³»,ç”¨ä¸€ä¸ªå­—å…¸è¡¨ç¤º,å…³é”®å­—æ˜¯ç±»åˆ«åç§°,å€¼æ˜¯å¯¹åº”çš„æ•°å­—ç¼–ç ã€‚


def get_clip_frame_paths(subject, count, onset, offset):
    """
    è·å–ä»onsetåˆ°offsetä¹‹é—´çš„æ‰€æœ‰å¸§è·¯å¾„ï¼ˆä¸ä¿è¯è¿ç»­ï¼‰
    :param subject: å—è¯•è€…ç¼–å·ï¼ˆå¦‚1, 2ç­‰ï¼‰
    :param count: å¾®è¡¨æƒ…åºåˆ—ç¼–å·ï¼ˆå¦‚1, 2, 3ç­‰ï¼‰
    :param onset: èµ·å§‹å¸§ç¼–å·
    :param offset: ç»“æŸå¸§ç¼–å·
    :return: å¸§è·¯å¾„åˆ—è¡¨
    """
    frame_paths = []
    subject_dir = os.path.join(data_root, f"{int(subject):02d}")  # å—è¯•è€…æ–‡ä»¶å¤¹è·¯å¾„ï¼Œå¦‚01, 02ç­‰
    clip_dir = os.path.join(subject_dir, 'color', f"{int(subject):02d}_{count}")  # å¾®è¡¨æƒ…åºåˆ—æ–‡ä»¶å¤¹è·¯å¾„ï¼Œå¦‚01/color/1_1

    # éå†ä»onsetåˆ°offsetçš„æ‰€æœ‰å¸§
    for idx in range(onset, offset + 1):
        frame_path = os.path.join(clip_dir, f"{idx}.jpg")  # å¸§æ–‡ä»¶å‘½åè§„åˆ™ä¸º373.jpgç­‰
        if os.path.exists(frame_path):  # åªæ·»åŠ å­˜åœ¨çš„å¸§
            frame_paths.append(frame_path)
        else:
            print(f'Warning: Frame {frame_path} does not exist, skipping.')
    return frame_paths


# ç”¨äºæ£€æµ‹å›¾ç‰‡ä¸­çš„å”¯ä¸€ä¸€å¼ äººè„¸å…³é”®ç‚¹
def detect_lmks(frame):
    """
    æ£€æµ‹å›¾ç‰‡ä¸­çš„å”¯ä¸€ä¸€å¼ äººè„¸å…³é”®ç‚¹
    :param frame: è¾“å…¥çš„å›¾åƒå¸§
    :return: äººè„¸å…³é”®ç‚¹å­—å…¸ï¼Œå¦‚æœæœªæ£€æµ‹åˆ°äººè„¸åˆ™è¿”å› None
    """
    try:
        lmks = face_recognition.face_landmarks(frame)
        if not lmks:  # å¦‚æœæœªæ£€æµ‹åˆ°äººè„¸
            print('Warning: No face detected in the frame.')
            return None
        return lmks[0]  # è¿”å›ç¬¬ä¸€å¼ äººè„¸çš„å…³é”®ç‚¹
    except Exception as e:
        print(f'Error detecting landmarks: {e}')
        return None

# ä»å›¾åƒä¸­è£å‰ªå‡ºç‰¹å®šåŒºåŸŸçš„cell
def get_cell(img, cell_location):
# img:åŸå§‹å›¾åƒ
# cell_locationï¼šç»†èƒåŒºåŸŸçš„å·¦ä¸Šå’Œå³ä¸‹è§’åæ ‡ç‚¹ç»„æˆçš„å…ƒç»„
    point1, point2 = cell_location
    cell = img[point1[1]:point2[1], point1[0]:point2[0]]
    return cell

# æ ¹æ®ç»™å®šçš„äººè„¸å…³é”®ç‚¹åæ ‡landmarks,è®¡ç®—å‡ºå„ä¸ªç»†èƒåŒºåŸŸçš„åæ ‡æ¡†
def get_cell_locations(lmks):
    # å®šä¹‰get_rectå‡½æ•°,å¯ä»¥ä¼ å…¥ä¸­å¿ƒç‚¹å’Œå®½åº¦è®¡ç®—åæ ‡æ¡† è¾“å‡ºä¸ºä¸­å¿ƒç‚¹åæ ‡å‡å»ä¸€åŠå®½åº¦çš„å·¦åæ ‡ å’Œ  ä¸­å¿ƒç‚¹åæ ‡åŠ ä¸Šä¸€åŠå®½åº¦çš„å³åæ ‡
    def get_rect(center, width):
        point1 = np.array(center) - int(width / 2)
        point2 = np.array(center) + int(width / 2)
        return tuple(point1), tuple(point2)
    # åˆ›å»ºä¸€ä¸ªç©ºçš„å­—å…¸cellsæ¥å­˜å‚¨æå–çš„ç»†èƒåŒºåŸŸåæ ‡ã€‚
    # è®¡ç®—ä¸Šå˜´å”‡åŒºåŸŸçš„å®½åº¦ä½œä¸ºç»†èƒçš„é»˜è®¤å®½åº¦cell_widthã€‚
    cells = {}
    cell_width = int((lmks['top_lip'][6][0] - lmks['top_lip'][0][0]) / 2)

    key = 'top_lip'# ä¸Šå˜´å”‡
    points = np.array(lmks[key])
    left_lip_rect = get_rect(points[0], cell_width)
    right_lip_rect = get_rect(points[6], cell_width)
    cells['left_lip'] = left_lip_rect
    cells['right_lip'] = right_lip_rect
    # å°†å¾—åˆ°çš„å·¦å³ç»†èƒåæ ‡æ¡†å­˜å…¥cellså­—å…¸ä¸­ã€‚

    key = 'chin' # ä¸‹å·´
    point = lmks[key][int(len(lmks[key]) / 2)]
    rect_point1 = (point[0] - int(cell_width / 2), point[1] - cell_width)
    rect_point2 = (point[0] + int(cell_width / 2), point[1])
    chin_rect = (rect_point1, rect_point2)
    # å°†æå–çš„ä¸‹å·´ç»†èƒåæ ‡æ¡†å­˜å…¥cellså­—å…¸
    cells['chin_rect'] = chin_rect

    key = 'nose_tip'
    point = lmks[key][0]
    left_nose_rect_point1 = (point[0] - cell_width, left_lip_rect[0][1] - cell_width)
    left_nose_rect_point2 = (point[0], left_lip_rect[0][1])
    left_nose_rect = (left_nose_rect_point1, left_nose_rect_point2)
    cells['left_nose'] = left_nose_rect

    point = lmks[key][4]
    right_nose_rect_point1 = (point[0], right_lip_rect[0][1] - cell_width)
    right_nose_rect_point2 = (point[0] + cell_width, right_lip_rect[0][1])
    right_nose_rect = (right_nose_rect_point1, right_nose_rect_point2)
    cells['right_nose'] = right_nose_rect

    key = 'left_eye'
    point = lmks[key][0]
    left_eye_rect_point1 = (point[0] - cell_width, int(point[1] - cell_width / 2))
    left_eye_rect_point2 = (point[0], int(point[1] + cell_width / 2))
    left_eye_rect = (left_eye_rect_point1, left_eye_rect_point2)
    cells['left_eye'] = left_eye_rect

    key = 'right_eye'
    point = lmks[key][3]
    right_eye_rect_point1 = (point[0], int(point[1] - cell_width / 2))
    right_eye_rect_point2 = (point[0] + cell_width, int(point[1] + cell_width / 2))
    right_eye_rect = (right_eye_rect_point1, right_eye_rect_point2)
    cells['right_eye'] = right_eye_rect

    left_point = lmks['left_eyebrow'][2]
    right_point = lmks['right_eyebrow'][2]
    center_point = (int((left_point[0] + right_point[0]) / 2),
                    int((left_point[1] + right_point[1]) / 2))

    center_eyebrow_rect = get_rect(center_point, cell_width)
    cells['center_eyebrow'] = center_eyebrow_rect

    left_rect_point1 = (int(center_point[0] - cell_width * 3 / 2),
                        int(center_point[1] - cell_width / 2))
    left_rect_point2 = (int(center_point[0] - cell_width * 1 / 2),
                        int(center_point[1] + cell_width / 2))
    left_eyebrow_rect = (left_rect_point1, left_rect_point2)
    cells['left_eyebrow'] = left_eyebrow_rect

    right_rect_point1 = (int(center_point[0] + cell_width * 1 / 2),
                         int(center_point[1] - cell_width / 2))
    right_rect_point2 = (int(center_point[0] + cell_width * 3 / 2),
                         int(center_point[1] + cell_width / 2))
    right_eyebrow_rect = (right_rect_point1, right_rect_point2)
    cells['right_eyebrow'] = right_eyebrow_rect

    return cells, cell_width

# è¾“å…¥å‚æ•°ä¸ºç»†èƒåœ¨å½“å‰æ—¶åˆ»tçš„å€¼cell_t,èµ·å§‹æ—¶åˆ»onsetçš„å€¼cell_onset,ç»“æŸæ—¶åˆ»offsetçš„å€¼cell_offset,ä»¥åŠä¸€ä¸ªè¡°å‡å¸¸æ•°cell_epsilon
import os


def get_clip_frame_paths(subject, count, onset, offset, data_root):
    """
    è·å–ä»onsetåˆ°offsetä¹‹é—´çš„æ‰€æœ‰å¸§è·¯å¾„ï¼ˆä¸ä¿è¯è¿ç»­ï¼‰
    :param subject: å—è¯•è€…ç¼–å·ï¼ˆå¦‚1, 2ç­‰ï¼‰
    :param count: å¾®è¡¨æƒ…åºåˆ—ç¼–å·ï¼ˆå¦‚1, 2, 3ç­‰ï¼‰
    :param onset: èµ·å§‹å¸§ç¼–å·
    :param offset: ç»“æŸå¸§ç¼–å·
    :param data_root: æ•°æ®æ ¹è·¯å¾„
    :return: å¸§è·¯å¾„åˆ—è¡¨
    """
    frame_paths = []
    subject_str = f"{int(subject):02d}"  # å°†subjectæ ¼å¼åŒ–ä¸ºä¸¤ä½æ•°å­—ï¼Œå¦‚01, 10, 31
    subject_dir = os.path.join(data_root, subject_str)  # å—è¯•è€…æ–‡ä»¶å¤¹è·¯å¾„ï¼Œå¦‚01, 10, 31

    # ç”Ÿæˆæ­£ç¡®çš„å¾®è¡¨æƒ…åºåˆ—æ–‡ä»¶å¤¹åç§°ï¼Œcountä¿æŒåŸå§‹æ•°å€¼
    clip_dir = os.path.join(subject_dir, 'color', f"{subject}_{count}")

    # éå†ä»onsetåˆ°offsetçš„æ‰€æœ‰å¸§
    for idx in range(onset, offset + 1):
        frame_path = os.path.join(clip_dir, f"{idx}.jpg")  # å¸§æ–‡ä»¶å‘½åè§„åˆ™ä¸º373.jpgç­‰
        if os.path.exists(frame_path):  # åªæ·»åŠ å­˜åœ¨çš„å¸§
            frame_paths.append(frame_path)
        else:
            print(f'Warning: Frame {frame_path} does not exist, skipping.')

    return frame_paths


def compute_cell_difference(cell_t, cell_onset, cell_offset, cell_epsilon):
    """
    è®¡ç®—å½“å‰å¸§ä¸èµ·å§‹å¸§ã€ç»“æŸå¸§ä»¥åŠå‰ä¸€å¸§ä¹‹é—´çš„å·®å¼‚
    :param cell_t: å½“å‰å¸§çš„ç»†èƒåŒºåŸŸ
    :param cell_onset: èµ·å§‹å¸§çš„ç»†èƒåŒºåŸŸ
    :param cell_offset: ç»“æŸå¸§çš„ç»†èƒåŒºåŸŸ
    :param cell_epsilon: å‰ä¸€å¸§çš„ç»†èƒåŒºåŸŸ
    :return: å·®å¼‚å€¼ï¼ˆæ ‡é‡ï¼‰
    """
    # è®¡ç®—å½“å‰å¸§ä¸èµ·å§‹å¸§çš„å·®å¼‚
    diff_onset = np.abs(cell_t - cell_onset)
    # è®¡ç®—å½“å‰å¸§ä¸ç»“æŸå¸§çš„å·®å¼‚
    diff_offset = np.abs(cell_t - cell_offset)
    # è®¡ç®—å½“å‰å¸§ä¸å‰ä¸€å¸§çš„å·®å¼‚
    diff_epsilon = np.abs(cell_t - cell_epsilon)

    # ç»¼åˆå·®å¼‚å€¼ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´æƒé‡ï¼‰
    difference = (diff_onset.mean() + diff_offset.mean()) / (diff_epsilon.mean() + 1e-6)  # é¿å…é™¤ä»¥0
    return difference

def compute_cell_features(frame_t, on_frame, off_frame, frame_epsilon):
    """
    è®¡ç®—å½“å‰å¸§çš„ç‰¹å¾
    :param frame_t: å½“å‰å¸§
    :param on_frame: èµ·å§‹å¸§
    :param off_frame: ç»“æŸå¸§
    :param frame_epsilon: å‰ä¸€å¸§
    :return: ç‰¹å¾å­—å…¸ï¼Œå¦‚æœæœªæ£€æµ‹åˆ°äººè„¸åˆ™è¿”å› None
    """
    lmks = detect_lmks(frame_t)  # æ£€æµ‹å½“å‰å¸§çš„å…³é”®ç‚¹
    if lmks is None:  # å¦‚æœæœªæ£€æµ‹åˆ°äººè„¸
        return None

    try:
        cell_locations, cell_width = get_cell_locations(lmks)
        cell_differences = {}
        frame_t = frame_t.astype(np.float32)
        on_frame = on_frame.astype(np.float32)
        off_frame = off_frame.astype(np.float32)
        frame_epsilon = frame_epsilon.astype(np.float32)

        for key in cell_locations:
            cell_location = cell_locations[key]
            cell_t = get_cell(frame_t, cell_location)
            cell_onset = get_cell(on_frame, cell_location)
            cell_offset = get_cell(off_frame, cell_location)
            cell_epsilon = get_cell(frame_epsilon, cell_location)

            cell_difference = compute_cell_difference(cell_t, cell_onset, cell_offset, cell_epsilon)
            cell_differences[key] = cell_difference
        return cell_differences
    except Exception as e:
        print(f'Error computing cell features: {e}')
        return None

# åœ¨ä¸€ä¸ªè§†é¢‘ç‰‡æ®µçš„æ‰€æœ‰å¸§ä¸Š,æå–æ¯å¸§çš„ç‰¹å¾,å¹¶æ‰¾åˆ°ç‰¹å¾å³°å€¼æœ€å¤§çš„å¸§,ä½œä¸ºé¡¶ç‚¹å¸§
def find_apex_frame_of_clip(frame_paths):
    """
    åœ¨ä¸€ä¸ªè§†é¢‘ç‰‡æ®µçš„æ‰€æœ‰å¸§ä¸Šï¼Œæå–æ¯å¸§çš„ç‰¹å¾ï¼Œå¹¶æ‰¾åˆ°ç‰¹å¾å³°å€¼æœ€å¤§çš„å¸§ï¼Œä½œä¸ºé¡¶ç‚¹å¸§
    :param frame_paths: å¸§è·¯å¾„åˆ—è¡¨
    :return: é¡¶ç‚¹å¸§è·¯å¾„ã€ç‰¹å¾å€¼åˆ—è¡¨ã€é¡¶ç‚¹å¸§çš„ç›¸å¯¹ç´¢å¼•
    """
    epsilon = 1  # ç”¨äºè®¡ç®—ç‰¹å¾çš„å¸§é—´éš”

    # è¯»å–èµ·å§‹å¸§å’Œç»“æŸå¸§
    on_frame = cv2.imread(frame_paths[0], cv2.IMREAD_GRAYSCALE)
    off_frame = cv2.imread(frame_paths[-1], cv2.IMREAD_GRAYSCALE)

    features = []

    # éå†æ‰€æœ‰å¸§ï¼Œè®¡ç®—ç‰¹å¾
    for i in range(epsilon, len(frame_paths)):
        frame_t = cv2.imread(frame_paths[i], cv2.IMREAD_GRAYSCALE)
        frame_epsilon = cv2.imread(frame_paths[i - epsilon], cv2.IMREAD_GRAYSCALE)

        # è®¡ç®—ç‰¹å¾
        current_features = compute_cell_features(frame_t, on_frame, off_frame, frame_epsilon)
        if current_features is None:  # å¦‚æœæœªæ£€æµ‹åˆ°äººè„¸æˆ–è®¡ç®—ç‰¹å¾å¤±è´¥
            features.append(0.0)  # æ·»åŠ é»˜è®¤ç‰¹å¾å€¼
            continue

        feature = sum(current_features.values()) / len(current_features)  # è®¡ç®—å¹³å‡ç‰¹å¾å€¼
        features.append(feature)

    # æ‰¾åˆ°ç‰¹å¾å³°å€¼æœ€å¤§çš„å¸§
    padding = [0.0] * epsilon
    features = np.array(padding + features)
    apex_frame_idx = features.argmax()
    apex_frame_path = frame_paths[apex_frame_idx]

    return apex_frame_path, features, apex_frame_idx


def draw_avg_plot(features, pred_apex_idx, data, clip_name):
    x = list(range(len(features)))
    plt.plot(x, features)
    plt.axvline(x=pred_apex_idx, label='pred apex idx at={}'.format(pred_apex_idx), c='red')
    plt.legend()
    plt.savefig('plots/{}/{}.png'.format(data, clip_name))
    plt.clf()
    plt.cla()
    plt.close()


def on_all_clips():
    """
    å¤„ç†æ‰€æœ‰å¾®è¡¨æƒ…åºåˆ—ï¼Œæ‰¾åˆ°é¡¶ç‚¹å¸§
    """
    # å®šä¹‰æ•°æ®æ ¹ç›®å½•è·¯å¾„
    data_root = r"D:\HTNet-master\NEW_MODEL\CASME_3"  # è®¾ç½®ä½ çš„æ•°æ®å­˜æ”¾æ ¹ç›®å½•è·¯å¾„

    # è¯»å–æ³¨é‡Šæ–‡ä»¶
    df = pd.read_excel(annotation_file)
    data_list = []  # ä½¿ç”¨å­—å…¸åˆ—è¡¨ä»£æ›¿å¤šä¸ªç‹¬ç«‹åˆ—è¡¨

    # éå†æ¯ä¸€è¡Œæ•°æ®
    with tqdm(total=len(df)) as progress_bar:
        for _, row in df.iterrows():
            subject = row['sub']  # å—è¯•è€…ç¼–å·
            count = row['count']  # å¾®è¡¨æƒ…åºåˆ—ç¼–å·
            onset = row['onset']  # èµ·å§‹å¸§
            offset = row['offset']  # ç»“æŸå¸§
            emotion = row['emotion']  # å¾®è¡¨æƒ…ç±»åˆ«

            # è·å–å¸§è·¯å¾„ï¼Œä¼ é€’ data_root å‚æ•°
            clip_frame_paths = get_clip_frame_paths(subject, count, onset, offset, data_root)

            # å¦‚æœå¸§è·¯å¾„ä¸ºç©ºï¼Œè·³è¿‡è¯¥åºåˆ—
            if not clip_frame_paths:
                print(f'Warning: No frames found for subject {subject}, count {count}. Skipping.')
                progress_bar.update(1)  # ä»ç„¶æ›´æ–°è¿›åº¦æ¡
                continue

            # æ‰¾åˆ°é¡¶ç‚¹å¸§
            apex_frame_path, features, apex_relative_idx = find_apex_frame_of_clip(clip_frame_paths)

            # æå–é¡¶ç‚¹å¸§ç¼–å·
            apex_frame_idx = int(os.path.basename(apex_frame_path).split('.')[0])  # ä»æ–‡ä»¶åä¸­æå–å¸§ç¼–å·

            # ä¿å­˜ç»“æœåˆ°å­—å…¸
            data_list.append({
                'data': 'CAS(ME)3',
                'subject': subject,
                'count': count,
                'label': label_dict.get(emotion, -1),
                'onset_frame': onset,
                'apex_frame': apex_frame_idx,
                'offset_frame': offset,
                'onset_frame_path': clip_frame_paths[0],
                'apex_frame_path': apex_frame_path,
                'off_frame_path': clip_frame_paths[-1]
            })

            progress_bar.update(1)

    # ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶
    result_df = pd.DataFrame(data_list)
    result_df.to_csv('CAS(ME)3_apex_.csv', header=True, index=None)



import os
import matplotlib.pyplot as plt

def draw_avg_plot(features, pred_apex_idx, data, clip_name):
    if not features:
        print("âš ï¸ Features list is empty! Skipping plot.")
        return

    x = list(range(len(features)))

    # åˆ›å»ºç›®æ ‡ç›®å½•
    save_dir = r'D:\HTNet-master\NEW_MODEL\plots'
    os.makedirs(save_dir, exist_ok=True)  # ç¡®ä¿ç›®å½•å­˜åœ¨
    save_path = os.path.join(save_dir, '{}.png'.format(clip_name))

    # è°ƒè¯•ä¿¡æ¯
    print("==== Debug Info ====")
    print(f"Features length: {len(features)}")
    print(f"Pred Apex Index: {pred_apex_idx}")
    print(f"Save path: {save_path}")
    print(f"Is save directory exists? {os.path.exists(save_dir)}")
    print("====================")

    # ç”»å›¾
    print(f"ğŸ“Š Drawing plot for: {clip_name}")
    print(f"ğŸ”¹ Feature length: {len(features)} | Pred Apex Index: {pred_apex_idx}")
    print(f"ğŸ’¾ Save path: {save_path}")

    plt.plot(x, features, label="Feature Curve")

    # æ£€æŸ¥ pred_apex_idx æ˜¯å¦åœ¨åˆæ³•èŒƒå›´å†…
    if 0 <= pred_apex_idx < len(features):
        plt.axvline(x=pred_apex_idx, label=f'Predicted Apex @ {pred_apex_idx}', c='red')
    else:
        print(f"âš ï¸ Warning: pred_apex_idx ({pred_apex_idx}) is out of range!")

    plt.legend()

    # å…ˆæ˜¾ç¤ºå›¾åƒï¼Œæ£€æŸ¥æ˜¯å¦æ­£ç¡®
    plt.show()

    try:
        plt.savefig(save_path)
        print(f"âœ… Plot saved at: {save_path}")
    except Exception as e:
        print(f"âŒ Error saving plot: {e}")

    plt.clf()
    plt.cla()
    plt.close()



if __name__ == '__main__':

    on_all_clips()